[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Cateloging my machine learning adventures."
  },
  {
    "objectID": "posts/palmerPenguins/index.html#abstract",
    "href": "posts/palmerPenguins/index.html#abstract",
    "title": "Palmer Penguins!",
    "section": "Abstract",
    "text": "Abstract\nWe intestigate the Palmer Penguin data set. We investigate quantitative and qualitative features that partion the set by species. We confirm our results with an automated feature selection process, and test four different model accuracy and speed (Decision Trees, Random Forrests, K-Nearest Neighbors, Logistic Regression)."
  },
  {
    "objectID": "posts/palmerPenguins/index.html#exploring-the-dataset",
    "href": "posts/palmerPenguins/index.html#exploring-the-dataset",
    "title": "Palmer Penguins!",
    "section": "Exploring the Dataset",
    "text": "Exploring the Dataset\nWe’ll first start by exploring the data set. I am most curious how different features partition the penguins by species. This will lend some context later on when we train our model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbove are box and wisker plots for penguin body mass and flipper length subdevided by species. Interesting, both Chinstrap and Adelie Penguins have similar distriubtions of these features. However, weight and flipper length clearly distinguishes Gentoo penguins from their counterparts. Moreover, flipper length appears to have a tighter spread accross Gentoo and Adelie penguins. Speaking of penguins, here’s the squad:\n\n\n\n\n\n\n\n\n\nChinstrap\n\n\n\n\n\n\n\nGentoo\n\n\n\n\n\n\n\nAdelie\n\n\n\n\n\nAs a certified penguin enjoyer, I also couldn’t help but notice that these penguins appear to have different types of beaks. The two features that correspond to this information are Culmen Length and Culmen depth. If we expect the beaks to be a distingishing feature, we might expect some seperation in the data set when we plot the two against eachother.\n\nWow! We are able to clearly distinguish each species of penguin by the ratio of their culmen length to culmen depth. This might suggest that among these three penguins within this region, beaks have adapted to suit each individuals speice’s unique needs like hunting, preening, and defense.\nI’m also curious about the species demographics accross the three islands.\n\nInterestingly, Adelie penguins live on all three islands, and are the only species residing on Torgersen island. Dream Island also contains Chinstrap Penguins, and Biscoe Island contains the entire Gentoo population.\nFinally, we’ll take a look at a pairplot for select quantiative features to see if there is anything else that might be useful:\n\nAlong the main diagonal, we can see the distriubtion of the features themselves for the three different species populations. We see that each feature only seperates out certain species. For example Flipper Length has one distinct mound centered right, but the two other mounds are overlapping. Besides culmen length to culmen depth, two other noteworthy charts our culmen length to flipper length, and culmen length to body mass."
  },
  {
    "objectID": "posts/palmerPenguins/index.html#feature-selection",
    "href": "posts/palmerPenguins/index.html#feature-selection",
    "title": "Palmer Penguins!",
    "section": "Feature Selection",
    "text": "Feature Selection\nThe intial exploration of the data suggestions that if we are clever about feature selection, we should be able to select features the cut the dataset by penguin species. To confirm this, we will use recursive features selection (REF). REF works by assigning a predictive socre to each feature. In this case, we’ll use linear regression. It then eliminates low-scoring features. The process is repeated until the desired number of features is reached. We’ll define our REF function as follows:\n\ndef select_features(df, target_column, n) :\n    #returns n most predictive features for target_column\n    x = df.drop(target_column, axis = 1)\n    y = df[target_column]\n    [x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size = 0.2, random_state = 42)\n    LR = LinearRegression()\n    rfe = RFE(estimator = LR, n_features_to_select = n)\n    rfe.fit(x_train, y_train)\n    return x.columns[rfe.support_]\n\nTo make things interesting, we’ll use two quantitative features and one qualitative feature. To do this, we’ll subdevide the dataset by quantitative features and qualitative features, and pass the augmented dataframe to our select features_features functions. In each case, we’ll look at the top 3 features:\n\n#Defining Cuts\nquantitativeFeatures = [\"Species\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\",  \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\nqualitativeFeatures = [\"Species\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Stage_Adult, 1 Egg Stage\", \"Clutch Completion_No\", \"Clutch Completion_Yes\", \"Sex_FEMALE\", \"Sex_MALE\"]\n#Selecting Features\nquantFeatures = utility.select_features(penguins[quantitativeFeatures], \"Species\", 3)\nqualFeatures = utility.select_features(penguins[qualitativeFeatures], \"Species\", 3)\n\nThe three best quantiative features are Culmen Length, Culmen Depth, and Delta 15 N. The three best qualitative features are Island_Biscoe, Island_Torgenrsen, and Clutch Completion. This confirms our suspicious in our initial analysis. For the quantitative features, we’ll take Culmen Length and Culmen Depth. In the intial data cleaning, I actually partitioned Island into three seperate columns, so we’ll just take Island as our single qualitative feature."
  },
  {
    "objectID": "posts/palmerPenguins/index.html#model-training",
    "href": "posts/palmerPenguins/index.html#model-training",
    "title": "Palmer Penguins!",
    "section": "Model Training",
    "text": "Model Training\n\nGiven the nature of this data set, there’s a high likelilhood we will be able to train a model with 100% accuracy. A better question to ask here is what types of models work well with the features that we choose. From our initial gander at the data, we saw that no single feature cleanly partitions the penguins by species. However, composite features like Culmen Length to Column depth appeared to have high predictive power. Regression might then be a good choice here; particulary, we’ll take a look at logistic regression.\nAnother important observation is that features can reduce the number of choices that the model has to make. For example, if a model is passed Torgersen Island, there is an 100% chance that it is looking at a Adelie penguin. Even if the model is passed Biscoe Island, it still narrows the number of choices down to two birds (Adelie and Gentoo). From here, other features can be used to classfy. This type of logic implicates decision trees and random forrests. We’ll test these as well.\nWe’ll define our predictive features and train the models as follows:\n\n#Defining features\npredictiveFeatures = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n#Initializing Models\ntree = DecisionTreeClassifier() #1\nRF = RandomForestClassifier() #2\nKN = KNeighborsClassifier() #3\nLR = LogisticRegression(max_iter = 1000000) #4\nmodels = [tree, RF, KN, LR]\nmodelNames = [\"Decision Tree\", \"Random Forrest\", \"K - Nearest Neighbors\", \"Logistic Regress\"]\na = []\ni = 0\n#Training and Testing\nfor model in models:\n\n    model.fit(penguins[predictiveFeatures], targetFeature)\n    pred = model.predict(testingPenguins[predictiveFeatures])\n    accuracy = accuracy_score(pred, testTargetFeature)\n    print(modelNames[i] + \" Accuracy: \" + str(accuracy))\n    i += 1\n\nThe accuracies on the testing set are as follows: The Decision Tree scored 98.5%, the Random Forrest 100%, K - Nearest Neighbors 98.5%, and Logistic Regress 100%. We can investigate the decision process of our model by taking a look at the decision boundaries and confusion matrix:\n\n\n\n\n\n\n\n\n\nDecision Boundaries\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n\n\n\nThe decision tree made one wrong classification, mistaking a Adelie penguin for a Gentoo. Examining the decision boundaries, we see that a majority of the penguins are easily partitioned into their respective species, with the exception for a few penguins which lie near the boundaries. Interesting, although Torgersen island only contained Gentoo penguins, the model seemed to expect that other species could live there.\n\n\n\n\n\n\n\n\n\nDecision Boundary\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n\n\n\nThe Random Forrest model correctly classified all the penguins. Unlike the Decision Tree Model, the Random Forrest was able to find that certain islands only contain certain species of penguins. Boundaries are also more linear, distinctlly partitioning islands into two decision regions.\n\n\n\n\n\n\n\n\n\nDecision Boundary\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n\n\n\nThe K-Nearest Neighbors Model mistook a Gentoo penguin for a Chinstrap penguin. Similar to the Decision Tree, the model assumed that all species of penguins may be present on each island. K-Nearest Neights also has “rough” decision boundaries, which likely reflects the mechanics of the model.\n\n\n\n\n\n\n\n\n\nDecision Boundary\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n\n\n\nLogistic Regression was able to correctly classify all penguins. Out of all the models, Logistic Regression appears to have the cleanest decision boundaries, with no points close to boundary. Finally, it is worth remarking that K-Nearest Neighbors and Decision Tree were able to train and predict on the data the fastest. This was followed by Logistic Regression and then the Random Forrest. This means that Logistic Regression is the fastest, accurate model."
  },
  {
    "objectID": "posts/palmerPenguins/index.html#discussion",
    "href": "posts/palmerPenguins/index.html#discussion",
    "title": "Palmer Penguins!",
    "section": "Discussion",
    "text": "Discussion\nOverall, our investigation suggests the a small number of features can produce high efficacy–If we are able to cleverly partition the data set. For toy data sets, automated methods such as recursive feature selection can aid in the feature selection process. Logistic Regression was the fastest, most accurate model. However, K-Nearest Neighbors and Decision Trees both produced a high degree of accuracy at about \\(\\frac{1}{6}^{th}\\) the speed. This makes them good options for large data sets (think billions of penguins) where we are O.K. with sacrificing accuracy for a boost in computation complexity. Random Forrests–although by far the slowest method–correctly classified all the penguins. This suggets that in more complex data sets where multiple features may be regquired to accuriately classify, Random Forrests can be a robust classifcation method."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#introduction",
    "href": "posts/OptimalDecisionMaking/index.html#introduction",
    "title": "Optimal Decision Making",
    "section": "Introduction",
    "text": "Introduction\nThe primary way through which a bank makes money is a loan. The bank will lend you some sum of money which you then must pay back over duration of the loan period, plus some interest. However, sometimes individuals may not be able to pay back their loan, causing them to default. Choosing who gets a loan is then a pivotal component of the bank’s profitability.\nToday, we will try to automate this process using a scoring function with a minimum threshold. We will design a profit maximizing algorithm, analyze its performance, and investigate its demographic impact."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#data-analysis",
    "href": "posts/OptimalDecisionMaking/index.html#data-analysis",
    "title": "Optimal Decision Making",
    "section": "Data Analysis",
    "text": "Data Analysis\nLet’s take a look at the data! First, let’s see what type of people are defaulting on their loans. While there are many features in the dataframe that we might use to extrapolate on demographic information, there are three of interest. First, is loan intent, which is subdevided into Venture, Education, Medical, Home Improvement, Personal, and Debt Consolidation.\n\n\n\n\n\n\n\n\n\nRepaid\n\n\n\n\n\n\n\nDeafulted\n\n\n\n\n\n\nLoan Intent by Loan Status\n\n\n\nRunning a chi square test on the data returns Chi Square Statistic of approximately 368 with confidence approximately 2.1114918454052173e-77. Clearly, whether or not someone defaults on their loans impacts the distriubtion of loan intent. However, a quick look at the charts reveals that the per-cateogry difference is plus/minus a few percents. For our purposes, this does not indicate a clear bias, and we may confirm this in the correlation matrix: Indeed, the correlation between loan status and loan intent is .09. However, this information will be useful when assessing algorithm performance.\nNext, we’ll take a look at loan amount subdevided by defaults. This will be particularly useful when assessing algorithm profitability.\n\nA quick glance at the histogram shows that amount seems to have a negligiable impact on defaults. Again, we may confirm this in the correlation matrix: loan amount has a .1 positive correlation with defaults. Finally, let’s look at home ownership. This is subdevided into those with morgages, full home ownership, renters, and an other category.\n\n\n\n\n\n\n\n\n\nLow Risk\n\n\n\n\n\n\n\nHigh Risk\n\n\n\n\n\nInterestingly, Renters comprise about 73% of individuals who defaulted on their loans but only 44% of those who repay them. We also see that, combined, home owners and inividuals with morgages make up about 26% of individuals who default, but 55% of individuals who repay their loans. We’ll also run a Chi Square Test on this feature, which results in a Chi-square statistic of approximately 1294 with confidence 2.913582391497053e-280! This makes qualitative sense: Individuals that own property are more likely to own assets, and be able to leverage said assets (home, financial, or otherwise) to repay loans. Homeownership also has a positive .22 correlation with loan status."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#feature-selection-and-model-training",
    "href": "posts/OptimalDecisionMaking/index.html#feature-selection-and-model-training",
    "title": "Optimal Decision Making",
    "section": "Feature Selection and Model Training",
    "text": "Feature Selection and Model Training\nThere are two clear candiate features to train on the model: Loan Percent of Income and Deafult on File. If one takes out a loan that is a greater percent of yearly, income, it can be hard for them to pay it back along with other expenses. Moreover, if one defaults on their loan for some reason, we can assume that they are likely to do it again in the future. These features have positive correlation with loans status of .38 and .14 respectively.\nFrom, our initial exploration, we also found that home ownership impacts loan repayment. How does it stack up against the loan’s percent of an individuals income? For convient analysis, call a loan amont that is greater than 50% of one’s income “high risk” and the converse “low risk”. We can then subdevide our dataset into into high risk loans and low risk, and look at the frequnecy of homeownership type in each.\n\n\n\n\n\n\n\n\n\nRepaid\n\n\n\n\n\n\n\nDeafulted\n\n\n\n\n\n\nHomeownership Breakdown For Repaid and Defaulted Loans\n\n\n\nloanPercentHomeownershipBAD.jpg\nWe see that renters make up a larger portion of high risk loans. This observation lends some insight to our initial finding: Perhaps renters may also be more likely to default on their loans since they are more likely to take out loans that are a higher percent of their income.\nFor our model, we use logistic regression, and we’ll train on the features discussed (.e.g Loan Percent Income, Default on File, and Homeownership Type). This yields on accuracy of 84% on the testing data–well within industry standards and acceptable for a simple regression model."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#profit-optmization",
    "href": "posts/OptimalDecisionMaking/index.html#profit-optmization",
    "title": "Optimal Decision Making",
    "section": "Profit Optmization",
    "text": "Profit Optmization\nThis is where the fun begins. First, let’s define a simple profit model for the bank. If an individual is able to repay their loan, let’s assume they did so over a 10 year period. On the other hand, if an individual defaults on their loan, we’ll assume that this occured after a 3 year period. We’ll also assume that the bank’s operating cost is 75% of the loan profit, to add some spice to our data (we don’t want to make things too easy). This leads to the following equations:\n\\[ REPAID = PRINCIPLE \\cdot (1 + INTEREST)^{10} - PRINCIPLE \\] \\[DEFAULTED = PRINCIPLE \\cdot (1 + INTEREST)^3 - PRINCIPLE\\]\nWe’ll use these equations to create a profit and loss column – denoted PnL –in both our training and testing data. We can do this as follows:\n\n    creditTest[\"loan_amnt\"] * (1 +  percentProfit * .01 * creditTest[\"loan_int_rate\"])**10 - creditTest[\"loan_amnt\"] (REPAID)\n    creditTest[\"loan_amnt\"]* (1 +  percentProfit * .01 * creditTest[\"loan_int_rate\"])**3 - 1.7 * creditTest[\"loan_amnt\"] (DEFAULT)\n\nNext, we’ll define a theoretical portfolio of loans to benchmark our algorithm’s performance. We do this by adding a loan to our portfolio in the testing set if and only if the PnL is positive. The sum of these loans is the maximum possible profit the bank can make. We can find this as follows:\n\n    theoreticalPNL = creditTest.loc[creditTest['PnL'] &gt; 0, 'PnL'].sum()\n\nNow we need to find our threshold. Rather than use the actual weights from the model, a more elegant solution is to simply look at the probability score the regression assigns to each entry. We can add this column to both the training and test set:\n\n    credit[\"probability_score\"] = LR.predict_proba(credit[interestingFeatures])[:, 1]\n    creditTest[\"probability_score\"] = LR.predict_proba(creditTest[interestingFeatures])[:, 1]\n\nWith the stage set, we can now design a tresholding algorithm. Ideally, we would like to transform this to a a calc I optmization problem where we have have profit \\(P\\) as a function of the treshold \\(T\\). To do this, we’ll discretize \\(T\\)’s domain by some constant \\(\\Delta\\). For each \\(T\\) value, we lend money if and only if the probability score is less than the treshold. We’ll the calculate PnL for the loans made, and record it as a function of \\(T\\).\nThere are two problems with with this approach. First, is time complexity. If \\(D\\) is the length of the data frame and \\(\\Delta\\) the descritizeation constant, this algorithm runs in \\(O(D \\cdot \\Delta)\\). While I can run this code on my 2016 macbook in under minutes, for larger datasets with more complex calcuations, this is bad practice. A more pressing issue is overfitting. By taking the optima of a single sample (e.g. the training data), we may maximize for the sample but not for potential data in the population (e.g. the trianing set).\nTo remedy these issues, we’ll take \\(n\\) sample of size \\(k\\), for each of which we will record the \\(T\\) value the maximizes profit. We then define a new statistic, call it \\(T^*\\), which is the mean of the sample maxizes (Thanks central limit theorem!). Notice that \\(n \\cdot k &lt; D \\Longrightarrow n \\cdot k \\cdot \\Delta &lt; D \\cdot \\Delta\\), we can theoretically accomplish this more quickly then the aforementioned method. This method is also quite emperically accurate at treshold determination for \\(n,k\\) small. This is acomplished with the following functions:\n\ndef sampleMaxProfit(credit, n, k, scoreRange):\n    #samples size n from df credit.\n    #tests tresholds across \n    T = scoreRange[0]\n    maxTuple = [0, 0]\n    sample = credit.sample(n)\n    delta_T = (abs(scoreRange[1] - scoreRange[0]))/k\n    while T &lt; scoreRange[1]: #can we do this without a loop?\n        PnL = sample.loc[sample['probability_score'] &lt;= T, 'PnL'].sum()\n        if (PnL &gt; maxTuple[0]):\n            maxTuple = [PnL, T]\n        T += delta_T\n    return maxTuple[1] \n\ndef optimalProfitScore(credit, iterations, n, k):\n    #Finds treshold score T that optmizes profit\n    testResult = []\n    scoreRange = [credit[\"probability_score\"].min(), credit[\"probability_score\"].max()]\n    for i in range(0, iterations):\n        testResult.append(sampleMaxProfit(credit, n, k, scoreRange))\n    npTestResult = np.array(testResult)\n    return np.mean(npTestResult)\n\nWhich produces the following result:\n\n\nNotice that our method (in orange) under estimates the optimal treshold value. This is because there is bias associated with our estimator. We can remedy this by multiplyiing by a proportionality constant. This works out to be about \\(1.05\\). The resulting curves look better for both the training and testing set:\n\n\n\n\n\n\n\n\n\nTraining Set\n\n\n\n\n\n\n\nTest Set\n\n\n\n\n\n\nProfit Curves.\n\n\n\nThe threshold value that maximize profit is 0.455 for both the training (right) and testing (left) set. Running the algorithm with 200 trials with sample size of 100 – which is less than the length of the data set at 22,000 – we recieve a treshold of 0.445."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#evaluation---bank",
    "href": "posts/OptimalDecisionMaking/index.html#evaluation---bank",
    "title": "Optimal Decision Making",
    "section": "Evaluation - Bank",
    "text": "Evaluation - Bank\nTime to put our top hats on. We’ll start by comparing the results of the algorithm against the theoretical loan portfolio. Our model has an accuracy of around 84%. The theoretical PnL is $12634399.24, the Model PnL is $7476722.014, and the Tresholded PnL is $7850920.35. Here Model PnL is the profit and loss if we use the model’s threshold. The Tresholded PnL is the profit and loss if we use our treshold. Using the tresholded PnL produces a 5% increase in profitability. However, both predictive methods capture just north of 60% of potential profits. While profit and is not a linear function of accuracy, if we assigned loan amounts reflecteive of the population to the 80% of the data we predicted correctly, we might expect it to be closer to 80% of thoeretical profits. This obseration suggests two, not-necessarily-mutually-exclusive possibilities. First, the algorithm is not giving loans to to high value loans. This would mean that we are leaving gainz on the table. Second, the algorithm is giving high value loans to people who are defaulting, which would puts a downward pressure on profit. Let’s investigate.\nFirst, we’ll partition the data set into individuals selected for a laon and individuals whose loan request is rejected. Call these categories Algorithm-Select and Algorithm-Reject repsectively. First, we consider defaults.\n\n\n\n\n\n\n\n\n\nSelection Default Loss\n\n\n\n\n\n\n\nReject Default Loss\n\n\n\n\n\n\nLoan Defaults for Alorithm Selections and Rejections\n\n\n\nOf those individuals who defaulted on their loans, the average loss for Algorithm-Select is $-5179. For the same default population, the average loss for Algorithm-Reject is $-8795. We also see that the loss histogram left-skewed for the Algorithm-Select, whereas it is centered farther form 0 for Algorithm-Reject. This suggests that the algorithm, on average, the Algorithm is doing a good job of not loosing money via defaults.\nWe now consider repayments.\n\n\n\n\n\n\n\n\n\nSelection Repayment Prfoit\n\n\n\n\n\n\n\nRejection Repayment Profit\n\n\n\n\n\n\nLoan Repayments for Alorithm Selections and Rejections\n\n\n\nAgain, of those individuals who reapid their loans, the average profit for Algorithm-Select is $2713. However the average profit in the Algorithm-Reject group is 5780. We see that the histogram for the Algorith-Select group is right skewed, whereas the histogram for Algorithm-Reject has a mound in $4000 - $6000 dollar range. The algorithm is not extending loans to potentially profitable individuals. Recall that one of the features we trained the model on was loan_percent income. While this was a good predictor of loan defaults, it (unsuprislingly) also has a positive correlation with loan amount for both default and repay groups.\n\nThis can make it difficult for our algorithm to correctly appraise high value loans leading to unrealized gains. Notice that for our given feature selection, we did maximize for profit. However, this was only for a single set of features. In that sense, this is question of model accuracy rather than optmization. Given the overlapping nature of the features in the data set, it is unlikely that this is case. Considering our algorithm is profitable, I would say that it recieves a satisfactory grade from the bank."
  },
  {
    "objectID": "posts/OptimalDecisionMaking/index.html#evaluation---demographic-impact",
    "href": "posts/OptimalDecisionMaking/index.html#evaluation---demographic-impact",
    "title": "Optimal Decision Making",
    "section": "Evaluation - Demographic Impact",
    "text": "Evaluation - Demographic Impact\nWe’ll now investigate the impact the model has on potential borrowers. We’ll use the same features we discussed at the beggining. First, lets look at loan intent breakdown.\n\n\n\n\n\n\n\n\n\nSelection Intent Breakdown\n\n\n\n\n\n\n\nRejection Intent Breakdown\n\n\n\n\n\n\nLoan Intent Breakdown for Algorithm Selections and Rejections.\n\n\n\nAgain, we see that their certainly is a change in the distriubtion. However, these changes are relatively minimal, which does not suggest that the algorithm is bias against loan intent. Looking at homeownership, we see that this tells a different story.\n\n\n\n\n\n\n\n\n\nSelection Ownership Types\n\n\n\n\n\n\n\nRejection Ownership Types\n\n\n\n\n\n\nHomeownership Type for Algorithm Selections and Rejections\n\n\n\nWe see that renters compose of 45.8% of Individuals seleclted for a loan, but 84.9% of individuals whose loan application was rejected. Individuals with morgages or who own homes make up about half of all loan selections, and around 14% of all loan rejections. If we make the same chart on the testing data, but instead look at historic defaults and repayments, we see that renters make up about 73% of individuals who default on their loans. Homeowners and invividuals with morgages make up about a quarter of loan defaults. Clearly, the algorithm we designed has made it harder for renters to get loans, thereby exascerbating existing inequality.\nMoreover, looking at the loan percent income by selection type used in the anlaysis for the bank, we see that our algorithm tends to select Individuals where loans are a lower portion of income. Commodities like healthcare and education tend to have a fixed, absolute cost regardless of economic background. Hence, this can make it harder for less afluent individuals to achieve wellbeing and economic advancement. This is confirmed looking at the mean income which is $70074 and $42644 for select and rejection groups respectively. Perhaps even more paradoxically, if homeownership / mortgage is a critical component in recieving a loan, how can we expect renters to own homes if they cannot recieve a loan to buy one in the first place?\nGiven this information, we might think that profitability is at odds with social responsibility (i.e. equality in loan extension). The synthesis here is notice that the bank left some profit on the table–some of which could be gained by lending to a more diverse group with respect to ownership type. Perhaps we need more features that partition the dataset, or a better model through which the data can be trained on. Or perhaps we should not be doing machine learning here at all. Maybe numbers will never represent abstract notions of trustworthiness and interpersonal relations. A question for another time (or blog post?)."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/blog-template/index.html",
    "href": "posts/blog-template/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/blog-template/index.html#math",
    "href": "posts/blog-template/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/WomenInDataScience/index.html",
    "href": "posts/WomenInDataScience/index.html",
    "title": "Women in Data Science",
    "section": "",
    "text": "Abstract\nWomen participation in STEM fields is up across must subdivisions. However, computer science and computing related subdisciplines lag behind. This article surveys some of the social, historical, and economic forces that contribute to this phenomenon. We examine how positive female role models contribute to retention and engagement. We consider one such instance; namely, Middlebury’s Women in Data Science conference.\n\n\nWomen in Data Science\nWomen in STEM fields have dramatically increased over the last 80 years. In 1960 women accounted for 8% of chemists. That number is now up to 39%. Over the same time period, women in biology increased from 25% to 50%. However, engineering fields have remained relatively stagnant, with women in computing related occupations declining since 1990. Currently, 1 in 5 computing degrees are awarded to women. Given that other STEM fields are approaching parity, what’s up with computer science?\nHistorically this was not the case. In the early 20th century, computing jobs were associated with secretarial and clerical positions, meaning they were often staffed by women. By WWII women made up the majority of programming jobs. In fact, women were some of the early trailblazers in computing: 6 female programmers worked on the first all-electronic computer; Grace Hopper designed, A-0, the first compiler; Margaret Hamilton engineered software for the Apollo Program, and Katherine Goble, Dorothy Vaughan, and Mary Jackson worked on calculations critical to the launch.\nHowever, the newly found prestige in the field of computer science actuated the decline in female participation. Increasing professionalization across the field meant a stronger connection to engineering; a male dominated industry due to its cultural and professional relations with heavy industry. One aspect in which this manifested was the creation of professional organizations, networks, and hierarchies that benefitted and encouraged male participation. Discriminatory hiring practices and stringent undergraduate admissions also put downward pressure on female participation. Perhaps most damning was the cultural association of the personal computer with boys and men. Primarily propagated through the gaming industry, this discouraged girls from pursuing computing careers at a young age. The complex matrix of cultural currents and historic events has left computing a male-dominated field.\nBut why do we even care? From a moral standpoint, it seems strange to construct social barriers that prevent individuals from entering a discipline based on uncontrollable traits. What if left-handed people were implicitly deterred from being doctors? Intuitively, we can agree that handedness ought not have a bearing on one’s qualifications to practice medicine. It is not a logical leap to say the same about gender in computer science. However, suppose you’re a pragmatist. Morals aside, the current system works, right? The problem is that when we culturally alienate half of the population from engineering and computing jobs, everyone misses out on the potential idea generation. This is particularly true in practical engineering and data science, where diverse backgrounds can often better inform application. Car seats were not initially designed with pregnant women in mind, leading to unnecessary deaths. Large data sets can benefit from the context of lived-experience. Perhaps most importantly, diversity can facilitate creativity and innovation: A culture of complacency breeds complacent ideas. Possessing a more accepting mindsend in relation to people can transfer to a more accepting one in relation to ideas.\nUnfortunately, increasing female participation in commuting is not as easy as inserting a column into a data set (although that itself can be tricky at times). Questions of acceptance and fairness raise themselves. How can we uphold meritocratic ideas when we clearly don’t live in one. Although laws are quick to change, culture and people are not. Perhaps one answer to this question is to showcase the work of outstanding female professionals in computing and computing-adjacent fields.\nWomen in engineering fields often describe feelings of isolation, lack of voice, and lack of belonging. Reports indicate that women find supervisors less receptive to their suggestions. They are less likely to agree that it is safe to speak up when compared to their male colleagues. Women suffer from a lack of other women in industry. This can make it harder for female computer scientists to find role models, and more likely to experience sexual harassment. Studies find that women are at increased risk of sexual discrimination in workplaces where they make up less than 25% of the labor force, and are less likely to speak up about these incidents to their male colleagues. Surveys also find women who left STEM careers were less likely to have training and development opportunities, support from coworkers or supervisors, and help balancing work and nonwork roles. Clearly, providing good role models and positive points of contact–namely in the form of other women–can create a more positive, safe work environment and increase recruitment and retention in the industry.\nOf course, this logic extends itself to undergraduate education as well. Middlebury’s Women in Data Science conference is a step towards creating a more equitable computing landscape–both inside and outside of the classroom. The conference also demonstrated the interdisciplinary nature of data science, showcasing data driven research from traditional ML specialists and computer scientists to field geographers and political scientists.\nDr. Amy Yuen started out the conference by asking Is the U.N. Security Democratic? The Security Council has five sitting members and 10 non-permanent members elected on an annual basis, and is one of the critical apparatuses for maintaining geopolitical stability. Sitting members possess veto powers and the ability to sponsor policies, whereas non-permanent only possess the latter. Given the power imbalances, Dr. Yuen turned to the data to find non-traditional avenues of power and metrics of representation. Her team constructed two theoretical council make-ups: One which represented a perfectly representative council, and the other a perfectly unrepresentative one. Using cumulative service year spent on the council per nation, and controlling for variables like council membership, Dr. Yuen was able to demonstrate that the council is mostly democratic.\nDr. Jessica L’Roe studies human-environment relationships in regions experiencing rapid change, and self-describes her work as “connecting people to pixels.” In the conference she presented her research in both Brazil and Africa. To prevent deforestation in Brazil, the government imposed an acreage cap on property size. Dr. L’Roe found that large landowners were registering under the size limits, explaining the increased rates of deforestation. In Africa, her team conducted a brute force, interpersonal survey of local property owners. Alongside two local women, they were able to conclude that external owners controlled much of the land, forcing local woodcutters to fell trees on restricted land. Dr. L’Roe also discussed the gender expectations associated with being a woman in science, and the importance of having positive, female role-models at critical points in her career.\nDr. Biester studies natural language processing where she hopes to better understand the human language through computational methods. Her recent work deals with manifestations of depression in text. Depression can be insidious in that depressed individuals may not even realize that they are displaying depressive tendencies. This can hamper effective treatment. To notice depression in its early stages, Dr. Biester developed a linear ML model to detect self-report patterns indicative of the underlying condition. To accomplish this, she turned to one of the internet’s largest sources of human text: reddit. Cleverly partitioning the text into control and test groups, she quite literally processed all of reddit, running calculations that lasted weeks.\nDr. Sarah Brown studies how data science can be integrated with human systems to improve outcomes. In her presentation, she discussed three “keys” that enabled her to find success in her work. Her first key arose in the context of developing a model to measure PTSD recovery progress. She realized that scores were only used to rank individuals who already possessed the condition, and were not scored relative to healthy individuals. The first key was then realizing that data resides in contexts. Her second experience dealt with the fundamentally incompatible notions of fairness: Error rate parity and calibration. She found that certain disciplines may be biased towards one definition, leading to the second key: disciplines are communities. Her final experience concerned work as a council member on the National Society of Black Engineers. She found that regional chapters were not accepting the program set by the national board. Ultimately, she discovered the disconnect was a restraint imposed by the universities through which the chapters were operating. Rather than pushing policy through, she realized the third key: meet people where they are.\nDr. Sara’s presentation also raised philosophical questions concerning notions of fairness and the scope of decision making within data science. However, Dr. Brown illustrated that fairness need not come at the expense of accuracy. She discussed one study which reviewed an algorithm for allocating social workers to people in need of medical care. The algorithm ultimately based decisions on who was in the most treatment programs; the logic here being that those individuals seeing more specialists would need more help scheduling treatment. The review found that the algorithm discriminated against black and brown individuals. In retrospect, this was obvious: Clearly, individuals who are seeing more doctors are likely to have time, money, and know-how to effectively navigate the healthcare system. The researchers proposed a revised algorithm that allocated social workers on the basis of symptoms, resulting in a far more equitable and accurate outcome.\nOne major reason women tend to leave computational jobs is a lack of work-related purpose. Academic and professional treatments of computation jobs can often exist in a vacuum of mathematical theory and computational mechanisms, without any clear context. Yet a common theme throughout all these presentations was the exact opposite: The use of context to construct experiments and meaningful interpret results. Theoreticians will always be important in driving the field of data science forwards. However, claiming that theory is the only way to do data science is as false as claiming that the domain is only for men.\n\n\nReflection\nI really enjoyed the presentations at the conference since they offered great insight into what type of research Middlebury (and other) professors are doing. The most interesting part of this blog post was researching some of the sociological forces that have contributed to a decline in women’s participation in computer science. I was particularly struck how “professionalization” of the field led to men taking a dominant role in the industry. I also never considered that living and/or working among a diverse population can lead to more diverse thinking. I am curious to learn more about contemporary thinking concerning the moral position of data science; particularly when data relates to people."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Women in Data Science",
    "section": "",
    "text": "Abstract\nWomen participation in STEM fields is up across must subdivisions. However, computer science and computing related subdisciplines lag behind. This article surveys some of the social, historical, and economic forces that contribute to this phenomenon. We examine how positive female role models contribute to retention and engagement. We consider one such instance; namely, Middlebury’s Women in Data Science conference.\n\n\nWomen in Data Science\nWomen in STEM fields have dramatically increased over the last 80 years. In 1960 women accounted for 8% of chemists. That number is now up to 39%. Over the same time period, women in biology increased from 25% to 50%. However, engineering fields have remained relatively stagnant, with women in computing related occupations declining since 1990. Currently, 1 in 5 computing degrees are awarded to women. Given that other STEM fields are approaching parity, what’s up with computer science?\nHistorically this was not the case. In the early 20th century, computing jobs were associated with secretarial and clerical positions, meaning they were often staffed by women. By WWII women made up the majority of programming jobs. In fact, women were some of the early trailblazers in computing: 6 female programmers worked on the first all-electronic computer; Grace Hopper designed, A-0, the first compiler; Margaret Hamilton engineered software for the Apollo Program, and Katherine Goble, Dorothy Vaughan, and Mary Jackson worked on calculations critical to the launch.\nHowever, the newly found prestige in the field of computer science actuated the decline in female participation. Increasing professionalization across the field meant a stronger connection to engineering; a male dominated industry due to its cultural and professional relations with heavy industry. One aspect in which this manifested was the creation of professional organizations, networks, and hierarchies that benefitted and encouraged male participation. Discriminatory hiring practices and stringent undergraduate admissions also put downward pressure on female participation. Perhaps most damning was the cultural association of the personal computer with boys and men. Primarily propagated through the gaming industry, this discouraged girls from pursuing computing careers at a young age. The complex matrix of cultural currents and historic events has left computing a male-dominated field.\nBut why do we even care? From a moral standpoint, it seems strange to construct social barriers that prevent individuals from entering a discipline based on uncontrollable traits. What if left-handed people were implicitly deterred from being doctors? Intuitively, we can agree that handedness ought not have a bearing on one’s qualifications to practice medicine. It is not a logical leap to say the same about gender in computer science. However, suppose you’re a pragmatist. Morals aside, the current system works, right? The problem is that when we culturally alienate half of the population from engineering and computing jobs, everyone misses out on the potential idea generation. This is particularly true in practical engineering and data science, where diverse backgrounds can often better inform application. Car seats were not initially designed with pregnant women in mind, leading to unnecessary deaths. Large data sets can benefit from the context of lived-experience. Perhaps most importantly, diversity can facilitate creativity and innovation: A culture of complacency breeds complacent ideas. Possessing a more accepting mindsend in relation to people can transfer to a more accepting one in relation to ideas.\nUnfortunately, increasing female participation in commuting is not as easy as inserting a column into a data set (although that itself can be tricky at times). Questions of acceptance and fairness raise themselves. How can we uphold meritocratic ideas when we clearly don’t live in one. Although laws are quick to change, culture and people are not. Perhaps one answer to this question is to showcase the work of outstanding female professionals in computing and computing-adjacent fields.\nWomen in engineering fields often describe feelings of isolation, lack of voice, and lack of belonging. Reports indicate that women find supervisors less receptive to their suggestions. They are less likely to agree that it is safe to speak up when compared to their male colleagues. Women suffer from a lack of other women in industry. This can make it harder for female computer scientists to find role models, and more likely to experience sexual harassment. Studies find that women are at increased risk of sexual discrimination in workplaces where they make up less than 25% of the labor force, and are less likely to speak up about these incidents to their male colleagues. Surveys also find women who left STEM careers were less likely to have training and development opportunities, support from coworkers or supervisors, and help balancing work and nonwork roles. Clearly, providing good role models and positive points of contact–namely in the form of other women–can create a more positive, safe work environment and increase recruitment and retention in the industry.\nOf course, this logic extends itself to undergraduate education as well. Middlebury’s Women in Data Science conference is a step towards creating a more equitable computing landscape–both inside and outside of the classroom. The conference also demonstrated the interdisciplinary nature of data science, showcasing data driven research from traditional ML specialists and computer scientists to field geographers and political scientists.\nDr. Amy Yuen started out the conference by asking Is the U.N. Security Democratic? The Security Council has five sitting members and 10 non-permanent members elected on an annual basis, and is one of the critical apparatuses for maintaining geopolitical stability. Sitting members possess veto powers and the ability to sponsor policies, whereas non-permanent only possess the latter. Given the power imbalances, Dr. Yuen turned to the data to find non-traditional avenues of power and metrics of representation. Her team constructed two theoretical council make-ups: One which represented a perfectly representative council, and the other a perfectly unrepresentative one. Using cumulative service year spent on the council per nation, and controlling for variables like council membership, Dr. Yuen was able to demonstrate that the council is mostly democratic.\nDr. Jessica L’Roe studies human-environment relationships in regions experiencing rapid change, and self-describes her work as “connecting people to pixels.” In the conference she presented her research in both Brazil and Africa. To prevent deforestation in Brazil, the government imposed an acreage cap on property size. Dr. L’Roe found that large landowners were registering under the size limits, explaining the increased rates of deforestation. In Africa, her team conducted a brute force, interpersonal survey of local property owners. Alongside two local women, they were able to conclude that external owners controlled much of the land, forcing local woodcutters to fell trees on restricted land. Dr. L’Roe also discussed the gender expectations associated with being a woman in science, and the importance of having positive, female role-models at critical points in her career.\nDr. Biester studies natural language processing where she hopes to better understand the human language through computational methods. Her recent work deals with manifestations of depression in text. Depression can be insidious in that depressed individuals may not even realize that they are displaying depressive tendencies. This can hamper effective treatment. To notice depression in its early stages, Dr. Biester developed a linear ML model to detect self-report patterns indicative of the underlying condition. To accomplish this, she turned to one of the internet’s largest sources of human text: reddit. Cleverly partitioning the text into control and test groups, she quite literally processed all of reddit, running calculations that lasted weeks.\nDr. Sarah Brown studies how data science can be integrated with human systems to improve outcomes. In her presentation, she discussed three “keys” that enabled her to find success in her work. Her first key arose in the context of developing a model to measure PTSD recovery progress. She realized that scores were only used to rank individuals who already possessed the condition, and were not scored relative to healthy individuals. The first key was then realizing that data resides in contexts. Her second experience dealt with the fundamentally incompatible notions of fairness: Error rate parity and calibration. She found that certain disciplines may be biased towards one definition, leading to the second key: disciplines are communities. Her final experience concerned work as a council member on the National Society of Black Engineers. She found that regional chapters were not accepting the program set by the national board. Ultimately, she discovered the disconnect was a restraint imposed by the universities through which the chapters were operating. Rather than pushing policy through, she realized the third key: meet people where they are.\nDr. Sara’s presentation also raised philosophical questions concerning notions of fairness and the scope of decision making within data science. However, Dr. Brown illustrated that fairness need not come at the expense of accuracy. She discussed one study which reviewed an algorithm for allocating social workers to people in need of medical care. The algorithm ultimately based decisions on who was in the most treatment programs; the logic here being that those individuals seeing more specialists would need more help scheduling treatment. The review found that the algorithm discriminated against black and brown individuals. In retrospect, this was obvious: Clearly, individuals who are seeing more doctors are likely to have time, money, and know-how to effectively navigate the healthcare system. The researchers proposed a revised algorithm that allocated social workers on the basis of symptoms, resulting in a far more equitable and accurate outcome.\nOne major reason women tend to leave computational jobs is a lack of work-related purpose. Academic and professional treatments of computation jobs can often exist in a vacuum of mathematical theory and computational mechanisms, without any clear context. Yet a common theme throughout all these presentations was the exact opposite: The use of context to construct experiments and meaningful interpret results. Theoreticians will always be important in driving the field of data science forwards. However, claiming that theory is the only way to do data science is as false as claiming that the domain is only for men.\n\n\nReflection\nI really enjoyed the presentations at the conference since they offered great insight into what type of research Middlebury (and other) professors are doing. The most interesting part of this blog post was researching some of the sociological forces that have contributed to a decline in women’s participation in computer science. I was particularly struck how “professionalization” of the field led to men taking a dominant role in the industry. I also never considered that living and/or working among a diverse population can lead to more diverse thinking. I am curious to learn more about contemporary thinking concerning the moral position of data science; particularly when data relates to people."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Women in Data Science\n\n\n\n\n\nAnalyzing the Leaky STEM Pipeline\n\n\n\n\n\nMar 28, 2024\n\n\nAlec Kyritsis\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science\n\n\n\n\n\nAnalyzing the Leaky STEM Pipeline.\n\n\n\n\n\nMar 28, 2024\n\n\nAlec Kyritsis\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins!\n\n\n\n\n\nClassifying Penguins\n\n\n\n\n\nApr 2, 2023\n\n\nAlec Kyritsis\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making\n\n\n\n\n\nMaximzing bank profit on loan returns using logistic regression and a sampling-determined threshold.\n\n\n\n\n\nMar 31, 2023\n\n\nAlec Kyritsis\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]